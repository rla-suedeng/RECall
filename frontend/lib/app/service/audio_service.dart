import 'dart:io';
import 'dart:typed_data';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:path_provider/path_provider.dart';
import 'package:audioplayers/audioplayers.dart';

class AudioService {
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  AudioPlayer? _player;

  /// ë§ˆì´í¬ ê¶Œí•œì„ ìš”ì²­í•©ë‹ˆë‹¤.
  Future<void> requestMicPermission() async {
    final status = await Permission.microphone.status;
    if (!status.isGranted) {
      await Permission.microphone.request();
    }
  }

  /// ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤.
  Future<void> startRecording() async {
    var status = await Permission.microphone.status;
    if (!status.isGranted) {
      status = await Permission.microphone.request();
      if (!status.isGranted) {
        throw Exception("ğŸ¤ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
      }
    }

    if (!_recorder.isStopped) {
      await _recorder.stopRecorder();
    }
    await _recorder.openRecorder();
    await _recorder.startRecorder(toFile: 'audio.aac');
  }

  /// ë…¹ìŒì„ ë©ˆì¶”ê³  byte ë°°ì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
  Future<Uint8List> stopRecordingAndGetBytes() async {
    final path = await _recorder.stopRecorder();
    if (path == null) {
      throw Exception("ë…¹ìŒ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
    }

    final file = File(path);
    if (!file.existsSync()) {
      throw Exception("ë…¹ìŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
    }

    return await file.readAsBytes();
  }

  /// ì˜¤ë””ì˜¤ byte ë°ì´í„°ë¥¼ ì¬ìƒí•©ë‹ˆë‹¤. (iOS ëŒ€ì‘: ì„ì‹œ íŒŒì¼ë¡œ ì²˜ë¦¬)
  // Future<void> playAudioBytes(Uint8List bytes) async {
  //   final tempDir = await getTemporaryDirectory();
  //   final filePath = '${tempDir.path}/response.mp3';
  //   final file = File(filePath);
  //   await file.writeAsBytes(bytes);

  //   // í”Œë ˆì´ì–´ ìƒˆë¡œ ìƒì„± (ë…¹ìŒ ì¤‘ ì¶©ëŒ ë°©ì§€)
  //   _player?.dispose();
  //   _player = AudioPlayer();

  //   await _player!.setVolume(1.0);
  //   await _player!.play(DeviceFileSource(filePath));
  // }

  // /// ìì› ì •ë¦¬
  // void dispose() {
  //   _recorder.closeRecorder();
  //   _player?.dispose();
  // }
  Future<void> playAudioBytes(Uint8List bytes) async {
    final tempDir = await getTemporaryDirectory();
    final filePath = '${tempDir.path}/response.mp3';
    final file = File(filePath);
    await file.writeAsBytes(bytes);

    // í”Œë ˆì´ì–´ ìƒˆë¡œ ìƒì„± (ë…¹ìŒ ì¤‘ ì¶©ëŒ ë°©ì§€)
    _player?.dispose();
    _player = AudioPlayer();

    // âœ… ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì • ì¶”ê°€ (ë…¹í™” ì¤‘ ì†Œë¦¬ í¬í•¨)
    await _player!.setAudioContext(const AudioContext(
      android: AudioContextAndroid(
        isSpeakerphoneOn: true,
        stayAwake: false,
        contentType: AndroidContentType.speech,
        usageType: AndroidUsageType.media,
        audioFocus: AndroidAudioFocus.gain,
      ),
      iOS: AudioContextIOS(
        category: AVAudioSessionCategory.playAndRecord,
        options: [AVAudioSessionOptions.defaultToSpeaker],
      ),
    ));

    await _player!.setVolume(1.0);
    await _player!.play(DeviceFileSource(filePath));
  }
}
